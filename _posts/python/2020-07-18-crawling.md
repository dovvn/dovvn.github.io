---
title:  "[파이썬 웹크롤링] 1. 기본 개념"
excerpt: "파이썬을 이용한 웹크롤링을 이해하고 주요 개념 정리"
permalink: /categories/python/web-crawling-01
author_profile: true
categories:
  - Python
tags:
  - Python
  - Crawling 
toc: true
toc_label: "목차"
toc_icon: "bookmark"
last_modified_at: 2020-07-18
---

{{page.excerpt}}  

# 공부 계획  
> 목표기간: 2020년 07월 18일 ~ 7월 31일(프로젝트 기간 포함)  
파이썬 웹크롤링을 공부하고 여러 소규모 프로젝트를 만든 후, 포폴용 플젝을 만드는것을 목표로 한다.
=> 프로젝트는 8월 까지 꼭 만들기! (하반기 시작 전)  <br/>

# 웹크롤링(Web Creawling)이란?
웹에서 데이터를 가져오는 행위   
이때, 웹에서 가져온 데이터를 내가 원하는 대로 가공하는 것을 **파싱(Parsing)**이라 한다.
예를 들어, 웹상의 콘텐츠는 html/css로 작성되었으므로 이를 가져와 보기에 편한 방식(ex.json)로 바꾸어 주는 것이 바로 파싱이다.  
**스크래핑(Scraping)**이란 데이터를 수집하는 모든 과정으로, 크롤링은 스크래핑의 방법 중 하나이다.  
=> 이를 정리하면, 웹크롤링을 한다, 파싱한다. == **웹상의 수많은 자료를 스크래핑(크롤링)하여 수집된 데이터를 파싱(가공)해서 내가 원하는 데이터를 추출하는 것**  <br/>

# 크롤링에 파이썬을 주로 사용하는 이유
* 웹크롤링에 필요한 라이브러리인  fake_useragent, BeautifulSoup, urllib, requests등이 있다.
* 파이썬에는 데이터 수집, 처리, 분석에 유용한 Pandas, TensorFlow(머신러닝) 패키지가 있다.  <br/>

# 크롤링을 하기 전 알아야하는 지식
## HTTP매서드

<br/>

# 파이썬 라이브러리 - 1)Requests
Python에서는 기본 라이브러리로 urllib가 제공되지만, Requests를 사용하면 좀 더 간결하게 HTTP요청을 할 수 있다.


